import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input

from .WGAN_Core import WGAN_Core
from model.metrics import reconstructionLoss

class WGAN(WGAN_Core):
    '''
    WGAN Class with Gradient Penalty and ContentLoss(a pretrained model)

    Generator:
        - input  shape   (None, 64, 64,3) by default
                 range   (-1,1)
        - output shape   (None,256,256,3) by default
                 range   (-1,1)

    Discriminator:
        - input  shape   (None, 256, 256, 3) by default
                 range   (-1,1)
        - output shape   (None, 1)
                 range   (-inf, +inf)
    '''
    def __init__(self, pretrained = 'resnet50', hyperimg_ids = [2,7,10,14],\
                 lr_shape = [64,64,3], hr_shape = [256,256,3] , *args, **kwargs):
        super().__init__(*args, **kwargs)
        '''
        Pretrained Models for Content Loss.
        Currently Support:
                    - ResNet50
                    - ResNet101

                    - VGG
                    - FCN101
        '''
        ## ** Hard Coded For now ** ##
        ### Needs Updates ### 
        self.pretrained_name = pretrained
        self.lr_shape = lr_shape
        self.hr_shape = hr_shape

        # Pretrained Model for the Content Loss
        self.pretrained = build_pretrained(pretrained, hyperimg_ids, hr_shape)
        self.pretrained.trainable = False

        self.hyper_ids = hyperimg_ids

    @staticmethod
    def build_pretrained(pretrained, hyperimg_ids, input_shape):
        if 'resnet50' == pretrained.lower():
            model = tf.keras.applications.ResNet50(input_shape = input_shape, include_top = False)
            # hyperimg_ids =  [0,11,12,13] for CAM
        elif 'resnet101' == pretrained.lower():
            model = tf.keras.applications.ResNet101(input_shape = input_shape, include_top = False)
            # hyperimg_ids = [2,22,24,25,27,28,29] for CAM
            # hyperimg_ids = [0,19,27,28,29,30]
        else:
            raise Exception('So far only supports resnet50 and resnet 101 for ContentLoss')

        outputs = [model.layers[i].output for i in hyperimg_ids]

        # Create a new Model that outputs the intermediate features from the pretrained model
        # Input shape (batch_sz, H, W, C)
        # Output Shape (batch_sz, fh, fw, c) for each layer 
        return Model(inputs = model.input, outputs = outputs)

    def contentLoss(self, img_fake:tf.Tensor, img_real:tf.Tensor):
        '''
        # MSE of Hyperimages(fake - real)
        # Hyper Images are constructed by taking intermediate output feature maps
        # from a Pretrained model (i.g.ResNet50)
        '''

        # Forward Pass of the Pretrained Model
        # which returns intermediate output feature maps at specified hyperimg_ids
        fakeFeatures = self.pretrained(img_fake)
        realFeatures = self.pretrained(img_real)

        ###******###
        total_loss = tf.reduce_sum([reconstructionLoss(fake, real) for fake, real in zip(fakeFeatures, realFeatures)])
        # record the total number of 'pixels'
        #total_num = tf.reduce_sum([tf.size(fake) for fake in fakeFeatures])

        # total_loss is the sum of MSE loss of each feature map
        # total_num should then be the num of feature maps
        total_num = tf.cast(len(self.hyper_ids), dtype = tf.float32)
        return total_loss / total_num

    def gradient_penalty(self, batch_size, x_fake, x_real):
        '''
        Calculate the Gradient Penalty.

        This loss is calculated on an interpolated image and added to the Discriminator Loss.
        '''

        # Get the interpolated image
        e_norm = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0) # Normal Distribution? Uniform Distribution?
        diff = x_fake - x_real
        interpolates = x_real + e_norm * diff

        # Gradients
        with tf.GradientTape() as tape:
          tape.watch(interpolates)
          # 1. Output of Critic using the interpolates
          pred = self.crt_model(interpolates, training = True)

        # Graidents w.r.t. the input = interpolates
        grads = tape.gradient(pred, [interpolates])[0]

        # Calculate the norm of the gradients
        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis = [1,2,3])) # All dimensions except for the batch dimension
        gradient_penalty = tf.reduce_mean((norm - 1.0) ** 2)

        return gradient_penalty

    def test_step(self, data): ###### New Z_samp every weight update instead of every complete training step
        x_real, l_real = data
        batch_size = tf.shape(x_real)[0]

        ## - x_real: Real Images from dataset
        ## - d_real: The discriminator's prediction of the reals
        ## - x_fake: Images generated by generator
        ## - d_fake: The discriminator's prediction of the fakes
        z_samp = self.sample_z(batch_size, training = False)
        x_fake = self.generate(z_samp, training = False)
        d_fake = self.criticize(x_fake, training = False)
        d_real = self.criticize(x_real, training = False)

        ###################################

        metrics = dict()

        '''
        all_funcs = {**self.loss_funcs, **self.acc_funcs}

        for key, func in all_funcs.items():
          metrics[key] = func(d_fake, d_real, x_fake, x_real)
        '''
        for key, func in self.loss_funcs:
            if 'd_loss' == key:
                metrics[key] = func(d_fake, d_real, None, None)
            elif 'g_loss' == key:
                metrics[key] = func(d_fake, None, x_fake, x_real) + self.contentLoss(x_fake, x_real)
            else:
                raise Exception('d_loss and g_loss are recommended for Keys of Losses Dictionary.')
        return metrics

    def train_step(self, data):
        x_real, l_real = data
        batch_size = tf.shape(x_real)[0]

        # For each Batch, as laid out in the original paper:
        # 1. Train the Discriminator and Get the Discriminator Loss
        # 2. Train the Generator and Get the generator Loss
        # 3. Calculate the Gradient Penalty
        # 4. Multiply this gradient Penalty with a constant weight
        # 5. Add the Gradient Penalty to the discriminator Loss
        # 6. Return the Generator and Discriminator Losses as a loss dictionary

        # Train the Discriminator First.
        # The original paper recommends training
        # the discriminator for 'n' more steps (typically 5) as compared to
        # one step of the generator. 

        # Train for Discriminator/Critic
        loss_fn = self.loss_funcs['d_loss']
        optimizer = self.optimizers['d_opt']

        for i in range(self.dis_steps):
          z_samp = self.sample_z(batch_size) ## New z_samp every update?
          # Gradient Tape
          with tf.GradientTape() as tape:
            # Generated Fake images from the Z_samp
            x_fake = self.generate(z_samp, training = True) # True for Gradient Penalty
            # Logits/Criticism from Discriminator for the Fake images
            d_fake = self.criticize(x_fake, training = True)
            # Logits/Criticism from Discriminator for the Real images
            d_real = self.criticize(x_real, training = True)

            # Default Discriminator Loss 
            d_cost = loss_fn(d_fake, d_real, None, None)
            # Gradient Penalty
            gp = self.gradient_penalty(batch_size, x_fake, x_real)
            # Total loss = Default D Loss + Gradient-Penalty
            d_loss = d_cost + gp * self.gp_weight

          # Get the Gradients of d_loss w.r.t. the Discriminator's parameters
          g = tape.gradient(d_loss, self.crt_model.trainable_variables)
          optimizer.apply_gradients(zip(g, self.crt_model.trainable_variables))


        # Train for Generator
        loss_fn = self.loss_funcs['g_loss']
        optimizer = self.optimizers['g_opt']

        for i in range(self.gen_steps):
          z_samp = self.sample_z(batch_size)
          # Gradient Tape
          with tf.GradientTape() as tape:
            # Generated Fake images from the z_samp
            x_fake = self.generate(z_samp, training = True)
            # Logits/Criticism from Discriminator for the fake images
            d_fake = self.criticize(x_fake, training = True)
            # Generator Loss
            ##  - -D(fake) + reconstructionLoss + contentLoss
            g_loss = loss_fn(d_fake, None, x_fake, x_real) + self.contentLoss(x_fake, x_real)

          # Get the gradients of g_loss w.r.t. the Generator's parameters
          g = tape.gradient(g_loss, self.gen_model.trainable_variables)
          optimizer.apply_gradients(zip(g, self.gen_model.trainable_variables))

        # Compute Final states for metric computation
        # new z_samp??
        z_samp = self.sample_z(batch_size)

        x_fake = self.generate(z_samp, training = False)

        d_fake = self.discriminate(x_fake, training = False)

        d_real = self.discriminate(x_real, training = False)

        #######################################

        metrics = dict()

        '''
        all_funcs = {**self.loss_funcs, **self.acc_funcs}

        for key, func in all_funcs.items():
            metrics[key] = func(d_fake, d_real)
        '''

        for key, func in self.loss_funcs:
            if 'd_loss' == key:
                metrics[key] = func(d_fake, d_real, None, None)
            elif 'g_loss' == key:
                metrics[key] = func(d_fake, None, x_fake, x_real) + self.contentLoss(x_fake, x_real)
            else:
                raise Exception('d_loss and g_loss are recommended for Keys of Losses Dictionary.')
        return metrics
